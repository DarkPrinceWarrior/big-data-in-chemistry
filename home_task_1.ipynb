{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd2\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from physlearn import Regressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer into xlsx format for convenience\n",
    "pd.read_csv(\"./data_original.csv\").to_excel(\"data_original.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data_original.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Date</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>measurement_error</th>\n",
       "      <th>measurement_wavelength</th>\n",
       "      <th>measurement_method</th>\n",
       "      <th>normalised_name</th>\n",
       "      <th>raw_value</th>\n",
       "      <th>specifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>10.1039/C4CP01679C</td>\n",
       "      <td>7/2/2014</td>\n",
       "      <td>Physical Chemistry Chemical Physics</td>\n",
       "      <td>The solvatochromic, spectral, and geometrical ...</td>\n",
       "      <td>DMF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rsc_cde_tables</td>\n",
       "      <td>CN(C)C=O</td>\n",
       "      <td>1.431</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>10.1016/j.jlumin.2018.04.026</td>\n",
       "      <td>4/12/2018</td>\n",
       "      <td>Journal of Luminescence</td>\n",
       "      <td>EU2O3DOPEDBRIGHTORANGEREDLUMINESCENTLITHIUMALU...</td>\n",
       "      <td>Oxygen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>el_cde_tables</td>\n",
       "      <td>O</td>\n",
       "      <td>1.3634</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>10.1016/j.jct.2004.09.021</td>\n",
       "      <td>1/5/2005</td>\n",
       "      <td>The Journal of Chemical Thermodynamics</td>\n",
       "      <td>PHYSICALPROPERTIESANISOLENALKANESTEMPERATURESB...</td>\n",
       "      <td>Octane</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>el_cde_tables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3947</td>\n",
       "      <td>nD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               DOI       Date  \\\n",
       "1287            10.1039/C4CP01679C   7/2/2014   \n",
       "2902  10.1016/j.jlumin.2018.04.026  4/12/2018   \n",
       "1992     10.1016/j.jct.2004.09.021   1/5/2005   \n",
       "\n",
       "                                     Journal  \\\n",
       "1287     Physical Chemistry Chemical Physics   \n",
       "2902                 Journal of Luminescence   \n",
       "1992  The Journal of Chemical Thermodynamics   \n",
       "\n",
       "                                                  Title    Name  \\\n",
       "1287  The solvatochromic, spectral, and geometrical ...     DMF   \n",
       "2902  EU2O3DOPEDBRIGHTORANGEREDLUMINESCENTLITHIUMALU...  Oxygen   \n",
       "1992  PHYSICALPROPERTIESANISOLENALKANESTEMPERATURESB...  Octane   \n",
       "\n",
       "      measurement_error measurement_wavelength measurement_method  \\\n",
       "1287                0.0                    NaN     rsc_cde_tables   \n",
       "2902                0.0                    NaN      el_cde_tables   \n",
       "1992                0.0                    NaN      el_cde_tables   \n",
       "\n",
       "     normalised_name raw_value specifier  \n",
       "1287        CN(C)C=O     1.431         n  \n",
       "2902               O    1.3634         n  \n",
       "1992             NaN    1.3947        nD  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   DOI                     5000 non-null   object \n",
      " 1   Date                    4593 non-null   object \n",
      " 2   Journal                 4593 non-null   object \n",
      " 3   Title                   4593 non-null   object \n",
      " 4   Name                    4996 non-null   object \n",
      " 5   measurement_error       5000 non-null   float64\n",
      " 6   measurement_wavelength  588 non-null    object \n",
      " 7   measurement_method      5000 non-null   object \n",
      " 8   normalised_name         2946 non-null   object \n",
      " 9   raw_value               5000 non-null   object \n",
      " 10  specifier               5000 non-null   object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для удобста ватаскивания значений через iloc\n",
    "column_index_dic = {col_name:index for index,col_name in enumerate(df.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed values ['Name']:  4\n"
     ]
    }
   ],
   "source": [
    "# В столбце \"Name\" есть пропущенные значения - 4 штуки \n",
    "print(\"Missed values ['Name']: \", df[\"Name\"].isna().sum())\n",
    "# В столбце \"Name\", заполним их исходя их столбца \"normalized name\"\n",
    "\n",
    "import requests \n",
    "\n",
    "def convert_smiles_to_name(smi):\n",
    "    try:\n",
    "        url =\"https://cactus.nci.nih.gov/chemical/structure/\" + smi+\"/iupac_name\" \n",
    "        res = requests.get(url)\n",
    "        return res.text.strip()\n",
    "    except:\n",
    "        return 'name not found'\n",
    "    \n",
    "for index in df[df[\"Name\"].isna()].index:\n",
    "    df.iloc[index,4] = convert_smiles_to_name(df.iloc[index,column_index_dic[\"normalised_name\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed values ['normalised_name']:  2054\n"
     ]
    }
   ],
   "source": [
    "# Теперь заполним пропуски в \"normalised_name\" через \"name\"\n",
    "\n",
    "# В столбце \"Name\" есть пропущенные значения - 4 штуки \n",
    "print(\"Missed values ['normalised_name']: \", df[\"normalised_name\"].isna().sum())\n",
    "# В столбце \"Name\", заполним их исходя их столбца \"normalized name\"\n",
    "\n",
    "def convert_names_to_smiles(norm_name):\n",
    "    try:\n",
    "        url =\"https://cactus.nci.nih.gov/chemical/structure/\" + norm_name+\"/smiles\" \n",
    "        res = requests.get(url)\n",
    "        return res.text.strip()\n",
    "    except:\n",
    "        return 'name not found'\n",
    " \n",
    "for index in df[df[\"normalised_name\"].isna()].index:\n",
    "    df.iloc[index,column_index_dic[\"normalised_name\"]] = convert_names_to_smiles(df.iloc[index,column_index_dic[\"Name\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на всякий случай, если есть, избавляемся от пробелов по краям строк\n",
    "df[\"DOI\"] = df[\"DOI\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка DOIs - первая интераця "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обраюотка DOI\n",
    "# Если есть пробелы, то начинаем обработку \n",
    "from bs4 import BeautifulSoup\n",
    "# индексы строк с пробелами в DOI\n",
    "index_rows= df[df[\"DOI\"].apply(lambda x: \" \" in x)].index\n",
    "\n",
    "slice_wrong_DOIs = df.iloc[index_rows,column_index_dic[\"DOI\"]]\n",
    "correct_slice_DOIs = []\n",
    "for doi in slice_wrong_DOIs.values:\n",
    "    try:\n",
    "        correct_doi = []\n",
    "        for symbol in doi:\n",
    "            correct_doi.append(symbol)\n",
    "            # все DOI длинее 11 символов)\n",
    "            if len(correct_doi)>11:\n",
    "                response = requests.get(f\"https://sci-hub.ru/{''.join(correct_doi)}\")\n",
    "                tag_value = BeautifulSoup(response.content, 'html.parser').find('title').get_text()\n",
    "                if tag_value != \"Sci-Hub: статья не найдена\":\n",
    "                    correct_slice_DOIs.append(\"\".join(correct_doi))\n",
    "                    break\n",
    "    except:\n",
    "        print(\"nothing\")\n",
    "\n",
    "# Вставляем исправленные значения в DOI\n",
    "df.iloc[index_rows,column_index_dic[\"DOI\"]] = correct_slice_DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем, какие статьи не ищутся и вытаскиваем индекс строк, таких статей\n",
    "responces = []\n",
    "doi_problems = []\n",
    "for doi in df[\"DOI\"]:\n",
    "    response = requests.get(f\"https://sci-hub.ru/{doi}\")\n",
    "    tag_value = BeautifulSoup(response.content, 'html.parser').find('title').get_text()\n",
    "    if tag_value == \"Sci-Hub: статья не найдена\":\n",
    "        doi_problems.append(doi)\n",
    "    responces.append(tag_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проблемнеы DOIs, есть дубликаты - удаляем\n",
    "doi_problems = set(doi_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собственно проблемные DOIs\n",
    "\n",
    "# План такой: убрать слова после цифр, эти DOIs прогнать через sci-hub\n",
    "# обновлять journal, title и date через crossref\n",
    "\n",
    "processed_doi_problems = dict()\n",
    "for doi in doi_problems:\n",
    "    uppers = [l for l in doi[::-1] if l.isupper()]\n",
    "    if len(uppers)>0: \n",
    "        processed_doi_problems[doi] = doi[:doi.find(uppers[0])]\n",
    "    else:\n",
    "        processed_doi_problems[doi] = doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Heat treatment effect on the structural and optical properties of AgInSe2 thin films\n",
      "Publication Date: 2002\n",
      "Journal: Vacuum\n",
      "DOI: 10.1016/s0042-207x(01)00417-1\n",
      "Title: The light transmission and distribution in an optical fiber coated with TiO2 particles\n",
      "Publication Date: 2003\n",
      "Journal: Chemosphere\n",
      "DOI: 10.1016/s0045-6535(02)00641-0\n",
      "DOI not found.\n",
      "Title: Theoretical study of structural, electronic and optical properties of InxGa1-xN alloys\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.08.083\n",
      "Title: The research on syntheses and properties of novel epoxy/polymercaptan curing optical resins with high refractive indices\n",
      "Publication Date: 2002\n",
      "Journal: Polymer\n",
      "DOI: 10.1016/s0032-3861(01)00573-0\n",
      "Title: Realization of tunable optical channel drop filter based on photonic crystal octagonal shaped structure\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.06.146\n",
      "Title: High-performance bimetallic film surface plasmon resonance sensor based on film thickness optimization\n",
      "Publication Date: 2016\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2016.05.085\n",
      "Title: Design of a promising silicon slot waveguide-based ultra-short low loss efficient polarization rotator for the mid-IR\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.11.064\n",
      "Title: Imaging the mammary gland and mammary tumours in 3D: optical tissue clearing and immunofluorescence methods\n",
      "Publication Date: 2016\n",
      "Journal: Breast Cancer Research\n",
      "DOI: 10.1186/s13058-016-0754-9\n",
      "Title: Optimization of electron bunch injection in dielectric laser acceleration\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.05.043\n",
      "Title: Design and optimization of diamond-shaped biosensor using photonic crystal nano-ring resonator\n",
      "Publication Date: 2015\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2015.06.037\n",
      "Title: Light propagation and interaction observed with electrons\n",
      "Publication Date: 2015\n",
      "Journal: Ultramicroscopy\n",
      "DOI: 10.1016/j.ultramic.2015.10.005\n",
      "Title: Substrate temperature influence on the optical and electrical properties of spray deposited Sn2S3 thin films\n",
      "Publication Date: 2016\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2016.08.083\n",
      "Title: A fast method for preparing a large diameter, three-dimensional photonic crystal infrared stealth material\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.11.135\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "Title: Gas permeation in thin films of “high free-volume” glassy perfluoropolymers: Part II. CO2 plasticization and sorption\n",
      "Publication Date: 2014\n",
      "Journal: Polymer\n",
      "DOI: 10.1016/j.polymer.2014.12.008\n",
      "Title: Light enhancement of surface nano-textured GaN based light emitting diodes using self-assembled Ni nano-masks\n",
      "Publication Date: 2015\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2015.10.116\n",
      "Title: Net-shaped pyramidal carbon-based ceramic materials designed for terahertz absorbers\n",
      "Publication Date: 2017\n",
      "Journal: Materials &amp; Design\n",
      "DOI: 10.1016/j.matdes.2017.02.002\n",
      "Title: Surface-initiated RAFT polymerization from vapor-based polymer coatings\n",
      "Publication Date: 2018\n",
      "Journal: Polymer\n",
      "DOI: 10.1016/j.polymer.2018.06.073\n",
      "Title: Modified solvatochromic equations for better estimation of ground and excited state dipole moments of p-aminobenzoicacid (PABA): Accounting for real shape over hypothetical spherical solvent shell\n",
      "Publication Date: 2017\n",
      "Journal: Journal of Photochemistry and Photobiology A: Chemistry\n",
      "DOI: 10.1016/j.jphotochem.2016.12.034\n",
      "Title: Composition and structure of fresh ammonia clouds on Jupiter based on quantitative analysis of Galileo/NIMS and New Horizons/LEISA spectra\n",
      "Publication Date: 2017\n",
      "Journal: Icarus\n",
      "DOI: 10.1016/j.icarus.2017.10.037\n",
      "Title: Design of a circular photonic crystal fiber with square air-holes for orbital angular momentum modes transmission\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.01.015\n",
      "Title: Design and analysis of single loop and double loop photonic crystal ring resonator based on hexagonal lattice structure\n",
      "Publication Date: 2018\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2018.10.157\n",
      "Title: Research of anti-ultraviolet nano-film structure based on the FDTD method\n",
      "Publication Date: 2015\n",
      "Journal: Optik\n",
      "DOI: 10.1016/j.ijleo.2015.10.042\n",
      "DOI not found.\n"
     ]
    }
   ],
   "source": [
    "# Проверяем обработанные статьи ячейкой выше processed_doi_problems\n",
    "\n",
    "problematic_doi = []\n",
    "for doi in list(processed_doi_problems.values()):\n",
    "    response = requests.get(f\"https://api.crossref.org/works/{doi}\")\n",
    "    if response.ok:\n",
    "        data = response.json()[\"message\"]\n",
    "        print(f\"Title: {data['title'][0]}\")\n",
    "        print(f\"Publication Date: {data['created']['date-parts'][0][0]}\")\n",
    "        print(f\"Journal: {data['container-title'][0]}\")\n",
    "        print(f\"DOI: {data['DOI']}\")\n",
    "    else:\n",
    "        problematic_doi.append(doi)\n",
    "        print(\"DOI not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.3389/fpls.2014.00', '10.1039/C6NR08470', '10.1039/C6TC05201', '10.1038/ncomms8']\n"
     ]
    }
   ],
   "source": [
    "# Проблемные статьи))\n",
    "print(problematic_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем старые DOIs новыми, \n",
    "# но остается два неразрешенных DOIs - ['10.1038/srep28', '10.3389/fpls.2014.00']\n",
    "for key,value in processed_doi_problems.items():\n",
    "    df.loc[df[\"DOI\"]==key,\"DOI\"] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['10.3389/fpls.2014.00', '10.1039/C6NR08470', '10.1039/C6TC05201', '10.1038/ncomms8'] удаляем эти DOIs (строки)\n",
    "for doi_prob in problematic_doi:\n",
    "    df = df.drop(df[df[\"DOI\"]==doi_prob].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполянем пропуски в (Date, Journal, Title)\n",
    "# Индексы пропусков у них одинаковые\n",
    "\n",
    "# Индексы пропусков у них одинаковые\n",
    "missed_index = df[df[\"Journal\"].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n",
      "DOI not found.\n"
     ]
    }
   ],
   "source": [
    "# Создаем список, который потом заполнить пропуски\n",
    "problematic_doi_2 = []\n",
    "values_fill = []\n",
    "for index in missed_index:\n",
    "    response = requests.get(f\"https://api.crossref.org/works/{df.loc[index,'DOI']}\")\n",
    "    if response.ok:\n",
    "        data = response.json()[\"message\"]\n",
    "        values_fill.append([data['created']['date-parts'][0][0],\n",
    "                            data['container-title'][0],data['title'][0]])\n",
    "    else:\n",
    "        problematic_doi_2.append(df.loc[index,'DOI'])\n",
    "        print(\"DOI not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем эти DOIs (строки)\n",
    "for doi_prob in problematic_doi_2:\n",
    "    df = df.drop(df[df[\"DOI\"]==doi_prob].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data_mod1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data_mod1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексы пропусков у них одинаковые - но изменились после удаления, поэтому заново\n",
    "missed_index = df[df[\"Journal\"].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем список, который потом заполнить пропуски (повторно, так как удалили некоторые строки)\n",
    "import time\n",
    "import requests\n",
    "\n",
    "problematic_doi_2 = []\n",
    "values_fill = []\n",
    "for index in missed_index:\n",
    "    response = requests.get(f\"https://api.crossref.org/works/{df.loc[index,'DOI']}\")\n",
    "    if response.ok:\n",
    "        data = response.json()[\"message\"]\n",
    "        values_fill.append([data['created']['date-parts'][0][0],\n",
    "                            data['container-title'][0],data['title'][0]])\n",
    "    else:\n",
    "        problematic_doi_2.append(df.loc[index,'DOI'])\n",
    "        print(\"DOI not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполянем пропуски в (Date, Journal, Title)\n",
    "df.loc[missed_index,\"Date\"] = [x[0] for x in values_fill]\n",
    "df.loc[missed_index,\"Journal\"] = [x[1] for x in values_fill]\n",
    "df.loc[missed_index,\"Title\"] = [x[2] for x in values_fill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data_mod1.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполняем пропуски в SMILES (через pubchempy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "\n",
    "def fill_smiles(mol_names):\n",
    "    smile_list = []\n",
    "    for mol_name in mol_names.values:\n",
    "        try:\n",
    "            smile = pcp.get_properties('CanonicalSMILES', mol_name, 'formula')[0]['CanonicalSMILES']\n",
    "            smile_list.append(smile)\n",
    "        except:\n",
    "            smile_list.append(None)\n",
    "    return smile_list\n",
    "\n",
    "mol_names = df.loc[df[\"normalised_name\"]==\"<h1>Page not found (404)</h1>\",\"Name\"]\n",
    "smiles = fill_smiles(mol_names)\n",
    "df.loc[df[\"normalised_name\"]==\"<h1>Page not found (404)</h1>\",\"normalised_name\"] = smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data_mod1.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполянем пропуски в measurement_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4985 entries, 0 to 4984\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   DOI                     4985 non-null   object \n",
      " 1   Date                    4985 non-null   object \n",
      " 2   Journal                 4985 non-null   object \n",
      " 3   Title                   4985 non-null   object \n",
      " 4   Name                    4985 non-null   object \n",
      " 5   measurement_error       4985 non-null   float64\n",
      " 6   measurement_wavelength  588 non-null    object \n",
      " 7   measurement_method      4985 non-null   object \n",
      " 8   normalised_name         4680 non-null   object \n",
      " 9   raw_value               4985 non-null   object \n",
      " 10  specifier               4985 non-null   object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 428.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_wavelength(df_row):\n",
    "  \n",
    "  \"\"\"Заполняем пропуски в колонке measurement_wavelength\"\"\"\n",
    "    \n",
    "  if pd.notna(df_row['measurement_wavelength']):\n",
    "    num = re.findall(r'[+]?\\d*\\.?\\d+|\\d+', df_row['measurement_wavelength'])\n",
    "    if 'μm'in df_row['measurement_wavelength']:\n",
    "      return float(num[0])*1000\n",
    "    else: \n",
    "      return float(num[0])\n",
    "  else:\n",
    "    if re.search(r'\\s*n*[D]', df_row['specifier']):\n",
    "      return 589\n",
    "    elif re.search(r'[\\s(]n.*d', df_row['specifier']):\n",
    "      return 588\n",
    "    elif re.search(r'[\\s(]n.*[fF]', df_row['specifier']):\n",
    "      return 486\n",
    "    elif re.search(r'[\\s(]n.*g', df_row['specifier']):\n",
    "      return 436\n",
    "    elif re.search(r'[\\s(]n.*e', df_row['specifier']):\n",
    "      return 546\n",
    "    num = re.findall(r'[+]?\\d*\\.?\\d+|\\d+', df_row['specifier'])\n",
    "    if len(num)!=0:\n",
    "      if 'nm' in df_row['specifier']:\n",
    "        return float(num[0])\n",
    "      elif 'μm' in df_row['specifier'] or 'μ  m'in df_row['specifier']:\n",
    "        return float(num[0])*1000\n",
    "      elif ('Å' in df_row['specifier']) or ('Å' in df_row['specifier']):\n",
    "        return float(num[0])/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем новую колонку, куда копируем имеющиеся значения 'measurement_wavelength' и дозаполняем пропуски\n",
    "df['measurement_wavelength'] = df.apply(lambda row: get_wavelength(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполняем пропуски в колонку 'measurement_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"measurement_error\"] = df[\"measurement_error\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurement_error(row):\n",
    "    values = re.findall(r\"[+]?\\d*\\.?\\d+|\\d+\", row['raw_value'])\n",
    "    values = [float(x) for x in values]\n",
    "    if len(values) == 1:\n",
    "        return 0\n",
    "    # если погрешность\n",
    "    elif values[0] > values[1]:\n",
    "        if row['measurement_error']==0:\n",
    "            return values[1]\n",
    "        else:\n",
    "            return row['measurement_error']\n",
    "    # если интервал\n",
    "    elif values[0] < values[1]:\n",
    "        if row['measurement_error']==0:\n",
    "            return (values[1] - values[0])/2\n",
    "        else:\n",
    "            return row['measurement_error']\n",
    "    else:\n",
    "        if row['measurement_error']!=0:\n",
    "            return row['measurement_error']\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Новые заненяи у measurement_error\n",
    "df[\"measurement_error\"] = df.apply(lambda row: get_measurement_error(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4985 entries, 0 to 4984\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   DOI                     4985 non-null   object \n",
      " 1   Date                    4985 non-null   object \n",
      " 2   Journal                 4985 non-null   object \n",
      " 3   Title                   4985 non-null   object \n",
      " 4   Name                    4985 non-null   object \n",
      " 5   measurement_error       4985 non-null   float64\n",
      " 6   measurement_wavelength  1273 non-null   float64\n",
      " 7   measurement_method      4985 non-null   object \n",
      " 8   normalised_name         4680 non-null   object \n",
      " 9   raw_value               4985 non-null   object \n",
      " 10  specifier               4985 non-null   object \n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 428.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data_mod1.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем дубликаты строк по DOI и Name и measurement_wavelength, measurement_method и normalised_name\n",
    "df = df.drop_duplicates(subset=[\"DOI\",\"Name\",\"measurement_wavelength\",\"measurement_method\",\"normalised_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data_mod1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4272 entries, 0 to 4984\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   DOI                     4272 non-null   object \n",
      " 1   Date                    4272 non-null   object \n",
      " 2   Journal                 4272 non-null   object \n",
      " 3   Title                   4272 non-null   object \n",
      " 4   Name                    4272 non-null   object \n",
      " 5   measurement_error       4272 non-null   float64\n",
      " 6   measurement_wavelength  922 non-null    float64\n",
      " 7   measurement_method      4272 non-null   object \n",
      " 8   normalised_name         3987 non-null   object \n",
      " 9   raw_value               4272 non-null   object \n",
      " 10  specifier               4272 non-null   object \n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 400.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
